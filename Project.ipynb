{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import des librairies et initialisation du Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a97f844631f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_svmlight_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow import keras \n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import catboost as cb\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import catboost as cb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Scraping des données de train et de test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Récupération des liens des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link=\"https://archive.ics.uci.edu/ml\"\n",
    "\n",
    "html=requests.get(base_link+\"/datasets/Poker+Hand\").text\n",
    "soup=BeautifulSoup(html,\"lxml\")\n",
    "table=soup.find(\"body\") \n",
    "name_part=soup.find(\"td\",{\"valign\":\"top\"})\n",
    "\n",
    "for link in table.find_all(\"a\"):\n",
    "    if link.get_text()=='Data Folder':\n",
    "        Data_folder_link=link.get('href')\n",
    "\n",
    "Data_folder_link=Data_folder_link.replace(\".\",\"\",2)\n",
    "\n",
    "\n",
    "html=requests.get(base_link+Data_folder_link ).text\n",
    "soup=BeautifulSoup(html,\"lxml\")\n",
    "table=soup.find(\"body\") \n",
    "\n",
    "for link in table.find_all(\"a\"):\n",
    "    \n",
    "    if link.get_text()=='poker-hand-testing.data':\n",
    "        test_link=link.get('href')\n",
    "    if link.get_text()=='poker-hand-training-true.data':\n",
    "        train_link=link.get('href')\n",
    "\n",
    "print(base_link+Data_folder_link+test_link)\n",
    "print(base_link+Data_folder_link+train_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du Datframe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = base_link+Data_folder_link+test_link\n",
    "test = pd.read_csv(test_path, encoding=\"latin1\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Import du Datframe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = base_link+Data_folder_link+train_link\n",
    "train = pd.read_csv(train_path, encoding=\"latin1\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension du jeu de train\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension du jeu de test\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomage des colonnes des jeux de train et de test\n",
    "test.columns=train.columns = ['Suit_of_card_1','Rank_of_card_1',\n",
    "                              'Suit_of_card_2','Rank_of_card_2',\n",
    "                              'Suit_of_card_3','Rank_of_card_3',\n",
    "                              'Suit_of_card_4','Rank_of_card_4',\n",
    "                              'Suit_of_card_5','Rank_of_card_5',\n",
    "                              'Poker_Hand']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout d'une colonne Datasplit Dans les jeux de train et de test\n",
    "train['datasplit']=\"train\"\n",
    "test['datasplit']=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list=pd.unique(result['Poker_Hand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Visualisation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Visualisation de la matrice de corrélation des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = result.corr()\n",
    "sn.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Visualisation de la répartition des classes de la colonne Poker_Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=len(unique_list)\n",
    "datadic={}\n",
    "for i,obs in enumerate(unique_list):\n",
    "    datadic[obs] = len(result.loc[(result['Poker_Hand'] == obs)] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker_hand_dic={0: \"Nothing in hand; not a recognized poker hand\",\n",
    "                1: \"One pair; one pair of equal ranks within five cards\",\n",
    "                2: \"Two pairs; two pairs of equal ranks within five cards\",\n",
    "                3: \"Three of a kind; three equal ranks within five cards\",\n",
    "                4: \"Straight; five cards, sequentially ranked with no gaps\",\n",
    "                5: \"Flush; five cards with the same suit\",\n",
    "                6: \"Full house; pair + different rank three of a kind\",\n",
    "                7: \"Four of a kind; four equal ranks within five cards\",\n",
    "                8: \"Straight flush; straight + flush\",\n",
    "                9: \"Royal flush; {Ace, King, Queen, Jack, Ten} + flush\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphique de la répartition des classes de la colonne Poker_Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (15,5)\n",
    "\n",
    "plt.bar(range(len(datadic)), datadic.values(), align='center')\n",
    "plt.xticks(range(len(datadic)), list(poker_hand_dic.values()),rotation=90)\n",
    "\n",
    "for a,b in zip(datadic.keys(), datadic.values()): \n",
    "     plt.text(a, b, str(b)     \n",
    "                +\" : \"+str(round(b/sum(datadic.values())*100))+\" %)\",      \n",
    "              horizontalalignment='center',color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=result.loc[(result['datasplit'] == \"train\")]\n",
    "train = train.reset_index(drop=True)\n",
    "train.pop('datasplit')\n",
    "test=result.loc[(result['datasplit'] == \"test\")]\n",
    "test = test.reset_index(drop=True)\n",
    "test.pop('datasplit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 0:10].values  \n",
    "y_train = train.iloc[:, 10].values \n",
    "X_test = test.iloc[:, 0:10].values  \n",
    "y_test = test.iloc[:, 10].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Modèle Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_train, y_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Modèle CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catboost\n",
    "#Random seeds are fixed at 1234 to make scores reproducible\n",
    "def CVandTest(X_train,y_train,X_test,y_test):\n",
    "    #80/20 train test split cross-validation\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "    cat = cb.CatBoostClassifier(\n",
    "        loss_function='MultiClassOneVsAll',\n",
    "        random_seed = 1234\n",
    "    )\n",
    "    cat_model1 = cat.fit(X_train,y_train,verbose=False) \n",
    "    \n",
    "    cat_predtrain=cat_model1.predict(X_train, prediction_type='Class')\n",
    "    \n",
    "    cat_predA = cat_model1.predict(X_test, prediction_type='Class')\n",
    "    cat_predLL = cat_model1.predict(X_test, prediction_type='Probability')\n",
    "\n",
    "    print(\"CV accuracy: {}\".format(accuracy_score(y_test,cat_predA)))\n",
    "    print(\"CV logloss: {}\".format(log_loss(y_test,cat_predLL)))\n",
    "    \n",
    "    #Training with all X,y data, testing with Xte,yte\n",
    "    cat_model2 = cat.fit(X_test,y_test,verbose=False)\n",
    "\n",
    "    cat_predAt = cat_model2.predict(X_test, prediction_type='Class')\n",
    "    cat_predLLt = cat_model2.predict(X_test, prediction_type='Probability')\n",
    "    \n",
    "\n",
    "    print(\"Test accuracy: {}\".format(accuracy_score(y_test,cat_predAt)))\n",
    "    print(\"Test logloss: {}\".format(log_loss(y_test,cat_predLLt)))\n",
    "    \n",
    "    return (cat_predtrain,cat_predA, cat_predLL, cat_predAt, cat_predLLt,cat_model1,cat_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat_predtrain,cat_predA, cat_predLL, cat_predAt, cat_predLLt,cat_model1,cat_model2) = CVandTest(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(cat_predAt,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(cat_predAt,y_test)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]],\n",
    "                  columns = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(cat_predtrain,y_train)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]],\n",
    "                  columns = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Modélisation avec du Deep Learning : Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape , output_shape):\n",
    "    net = keras.Sequential([\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(2048 ,input_shape=input_shape , activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(2048 , activation='relu' ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(output_shape , activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    net.compile(optimizer=optimizer , loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    return net\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train)\n",
    "Y_test = keras.utils.to_categorical(y_test)\n",
    "net = model((X_train.shape[1] , ) , Y_train.shape[1])\n",
    "net.fit(X_train , Y_train , epochs=50 , batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(predictions , y):\n",
    "    class_diff = predictions - y\n",
    "    count = 0\n",
    "    for i in range(class_diff.shape[0]):\n",
    "        if class_diff[i] == 0:\n",
    "            count += 1\n",
    "    return count / class_diff.shape[0]\n",
    "    \n",
    "\n",
    "predictions = np.argmax(net.predict(X_train , batch_size=256) , axis=1)\n",
    "conf_matrix = confusion_matrix(y_train , predictions)\n",
    "\n",
    "print('\\n---Train---\\n')\n",
    "print(conf_matrix)\n",
    "print('precision : ' , compute_precision(predictions , y_train))\n",
    "    \n",
    "predictions = np.argmax(net.predict(X_test , batch_size=256) , axis=1)\n",
    "conf_matrix = confusion_matrix(y_test , predictions)\n",
    "\n",
    "print('\\n---Test---\\n')\n",
    "print(conf_matrix)\n",
    "print('precision : ' , compute_precision(predictions , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = compute_precision(predictions , y_train)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]],\n",
    "                  columns = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = compute_precision(predictions , y_test)\n",
    "df_cm = pd.DataFrame(array, index = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]],\n",
    "                  columns = [i for i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de GridSearch avec CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "          'iterations':[250,100,500,1000],\n",
    "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "          'l2_leaf_reg':[3,1,5,10,100],\n",
    "          'border_count':[32,5,10,20,50,100,200],\n",
    "          'ctr_border_count':[50,5,10,20,100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cb.CatBoostClassifier(\n",
    "        loss_function='MultiClassOneVsAll',\n",
    "        random_seed = 1234, task_type = \"GPU\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cb.CatBoostClassifier(\n",
    "        loss_function='MultiClassOneVsAll',\n",
    "        random_seed = 1234)\n",
    "cat_model = cat.fit(X_train,y_train,verbose=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "         \n",
    "grid= grid_search.GridSearchCV(cat, params, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testd=cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (grid.best_score_, grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_param_tune(params,train,train_label,cat_dims=None,n_splits=3):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(ps.grid_search(['border_count']),\n",
    "                      ps.grid_search(['ctr_border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth'])):\n",
    "        res = crossvaltest(prms,train_set,train_label,cat_dims,n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res,prms)\n",
    "        print(res,prms,s'best:',ps.bestscore(),ps.bestparam())\n",
    "    return ps.bestparam()\n",
    "\n",
    "bestparams = catboost_param_tune(params,train_set,train_label,cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model1 = cat.fit(X_train,y_train,verbose=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
